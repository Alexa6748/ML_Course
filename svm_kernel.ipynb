{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexa6748/ML_Course/blob/main/svm_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7kPCCqM8DXX"
      },
      "source": [
        "# Kernels for hand-made SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cH4kN4A8DXh"
      },
      "source": [
        "**In this homework we will again look at SVM kernels and will write and test rbf kernel for our own implementation.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9O4Z5ev8DXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518e294a-a3b4-47d6-fce9-ffdc9bee0521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-12 19:10:08--  https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_03_svm/svm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4156 (4.1K) [text/plain]\n",
            "Saving to: ‘svm.py’\n",
            "\n",
            "\rsvm.py                0%[                    ]       0  --.-KB/s               \rsvm.py              100%[===================>]   4.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-12 19:10:08 (56.3 MB/s) - ‘svm.py’ saved [4156/4156]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "If you are using Google Colab, uncomment the next line to download `svm.py`\n",
        "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
        "'''\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_03_svm/svm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2OP46HZ8DXl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# use seaborn plotting defaults\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnBbZWyJ8DXl"
      },
      "outputs": [],
      "source": [
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "    \"\"\"Plot the decision function for our SVM class\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    # create grid to evaluate model\n",
        "    x = np.linspace(xlim[0], xlim[1], 50)\n",
        "    y = np.linspace(ylim[0], ylim[1], 50)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.predict(xy).reshape(X.shape)\n",
        "    # plot decision boundary and margins\n",
        "    CS = ax.contourf(X, Y, P, origin='lower', cmap='autumn', alpha=0.1)\n",
        "    plt.colorbar(CS, ax=ax, shrink=0.8, extend='both')\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqoT4oYC8DXn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "from sklearn.svm import SVC # \"Support vector classifier\"\n",
        "\n",
        "X, y = make_circles(150, factor=.1, noise=.1, random_state=42)\n",
        "\n",
        "X_test, y_test = X[100:], y[100:]\n",
        "X, y = X[:100], y[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNVIBQFz8DXo"
      },
      "source": [
        "### Sklearn realization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS4ApyrP8DXp"
      },
      "outputs": [],
      "source": [
        "clf = SVC(kernel='linear').fit(X, y)\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBoghnZy8DXr"
      },
      "outputs": [],
      "source": [
        "clf = SVC(kernel='rbf').fit(X, y)\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZ3mEP58DXs"
      },
      "source": [
        "## Let's look at our realization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcPwQ2GT8DXs"
      },
      "source": [
        "### You need to open svm.py file and add all missed lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XdhVJnw8DXt"
      },
      "source": [
        "Linear SVM __primal__ optimization problem can be formulated as\n",
        "\n",
        "$$ \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - y_i (w X_i - b)) + \\lambda ||w||_2 \\to \\min_w $$\n",
        "\n",
        "This problem can be solved with gradient or sub-gradien methods.\n",
        "\n",
        "-----\n",
        "Whereas __dual__ optimization problem formulates as follows:\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n c_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n y_i c_i (X_i \\cdot X_j ) y_j c_j \\to \\max_{c_1,...,c_n} \\\\ \\text{subject to} \\\\\n",
        "\\sum_{i=1}^n c_iy_i=0 \\\\\n",
        "0 \\leq c_i \\leq \\frac{1}{2n\\lambda} \\forall i\n",
        "$$\n",
        "\n",
        "Where $W = \\sum_{i=1}^n c_i y_i X_i$.\n",
        "\n",
        "In this quadratic optimization problem we can use kernel trick: <br/>\n",
        "introduce fucntion $K(X_i, X_j) = \\phi (X_i) \\phi (X_j)$ and change dot products in our optimization problem\n",
        "\n",
        "Then we have\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n c_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n y_i c_i K(X_i, X_j) y_j c_j \\to \\max_{c_1,...,c_n} \\\\\n",
        "\\text{subject to} \\\\\n",
        "\\sum_{i=1}^n c_iy_i=0 \\\\\n",
        "0 \\leq c_i \\leq \\frac{1}{2n\\lambda} \\forall i\n",
        "$$\n",
        "\n",
        "$W = \\sum_{i=1}^n c_i y_i \\phi(X_i)$\n",
        "\n",
        "In quadratic programming we can straightforwardly add kernel function, but it is not that simple, if we want to use gradient algorithms.\n",
        "\n",
        "----\n",
        "However primal optimization problem with kernels can be formulated like (see [Olivier Chapelle, 2006](https://www.cs.utah.edu/~piyush/teaching/svm-solving-primal.pdf)):\n",
        "\n",
        "$$f(x) = \\sum_{i=1}^n \\beta_i K(x_i, x)$$\n",
        "\n",
        "$$K: K_{i,j} = K(x_i, x_j)$$\n",
        "\n",
        "$$ \\lambda \\vec{\\beta^T} K \\vec{\\beta} + \\sum_{i=1}^n L(y_i, K_i^T \\vec{\\beta}) \\to \\min_{\\vec{\\beta}}$$\n",
        "\n",
        "where L is Hinge loss: $L(y_i, K_i^T \\vec{\\beta}) = \\max(0, 1 - y_i (K_i^T \\vec{\\beta}))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6H4N5GG8DXu"
      },
      "source": [
        "#### Radial basis function kernel.\n",
        "\n",
        "####  The RBF kernel on two samples x and x', represented as feature vectors in some input space, is defined as:\n",
        "\n",
        "## $K(x,x') = \\exp \\big{[}- \\frac{||x-x'||^2}{2 \\sigma^2} \\big{]}.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab8dlcNC8DXu"
      },
      "source": [
        "### Let's look how it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz40hQmn8DXu"
      },
      "outputs": [],
      "source": [
        "from svm import SVM, rbf\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QybyNGL8DXv"
      },
      "outputs": [],
      "source": [
        "y[y==0] = -1 # for convenience with formulas\n",
        "y_test[y_test==0] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-RVZvvD8DXv"
      },
      "outputs": [],
      "source": [
        "clf = SVM(epochs=3, lr=1, batch_size=20, verbose=True)\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJwDtJry8DXw"
      },
      "outputs": [],
      "source": [
        "clf = SVM(epochs=100, lr=0.1, batch_size=20, verbose=True, kernel_function=rbf)\n",
        "clf.fit(X, y)\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1Fsdpl58DXw"
      },
      "outputs": [],
      "source": [
        "assert accuracy_score(y_test, pred) > 0.95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XkpPHvN8DXx"
      },
      "source": [
        "## Our model with rbf kernel can learn this dataset too."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}